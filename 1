
void kernel(float *a)
__global__ void kernel(float * c,float * a,int * b, int tmp)
{
  int i;
  i = blockIdx.x * blockDim.x + threadIdx.x;
 
  if(i <10){
    tmp += i;
    c[i] = (a[i] + b[i]);
}  
}
#include <stdio.h>

int main()
{
  int i;
  int j;
  int k;
  int tmp;
  float a[10UL];
  int b[10UL];
  float c[10UL];
  for (i = 0; i < 10; i++) {
    a[i] = i;
    b[i] = (i + 1);
  }
 
  /***** Starting Parallalization *****/
  //declare device variables
  float elapsedTime;
  cudaEvent_t start, stop;
  cudaEventCreate(&start);
  cudaEventCreate(&stop);
float *  device_c;
float *  device_a;
int *  device_b;
 
  //Allocate memory space in the GPU
  cudaMalloc((void **) &device_c, sizeof(c));
  cudaMalloc((void **) &device_a, sizeof(a));
  cudaMalloc((void **) &device_b, sizeof(b));
 
  //Copy from host to device
  cudaMemcpy(device_c, c, sizeof(c), cudaMemcpyHostToDevice);
  cudaMemcpy(device_a, a, sizeof(a), cudaMemcpyHostToDevice);
  cudaMemcpy(device_b, b, sizeof(b), cudaMemcpyHostToDevice);
 
  //launch kernel function
  dim3 numThreads(32,1);
  dim3 blocks((10+ 31)/32, 1);
  cudaEventRecord(start, 0);
  kernel<<<blocks,numThreads>>>(device_c,device_a,device_b, tmp);
  cudaEventRecord(stop, 0);
  cudaEventSynchronize(stop);
  cudaEventElapsedTime(&elapsedTime, start, stop);
  printf("the elapsed time is %f\n", elapsedTime);
 
  //copy back from device to host 
  cudaMemcpy(c, device_c, sizeof(c), cudaMemcpyDeviceToHost);
  cudaMemcpy(a, device_a, sizeof(a), cudaMemcpyDeviceToHost);
  cudaMemcpy(b, device_b, sizeof(b), cudaMemcpyDeviceToHost);
 
  /***** Ending Parallalization *****/
  for (j = 0; j < 10; j++) {
    for (k = 0; k < 100; k++) {
      c[j] = (a[j] + 1);
    }
  }
  return 0;
}
